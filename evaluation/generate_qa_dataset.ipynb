{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generate QA Dataset from PDFs\n",
        "\n",
        "This notebook helps you create a QA dataset for evaluation by automatically generating questions and reference answers from your uploaded PDFs.\n",
        "\n",
        "## How it works:\n",
        "1. The system retrieves diverse content from your uploaded PDFs\n",
        "2. Uses LLM to generate questions based on the content\n",
        "3. Uses LLM to generate reference answers for each question\n",
        "4. Saves the dataset in the required JSON format\n",
        "\n",
        "## Setup\n",
        "- FastAPI server must be running on `http://localhost:8000`\n",
        "- PDFs must be uploaded to the system\n",
        "- OpenAI API key is required (for generating questions and answers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Libraries imported\n",
            "API Base URL: http://localhost:8000\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "import json\n",
        "import requests\n",
        "from typing import List, Dict\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# Configuration\n",
        "API_BASE_URL = \"http://localhost:8000\"\n",
        "OUTPUT_DIR = Path(\".\")\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "print(\"✓ Libraries imported\")\n",
        "print(f\"API Base URL: {API_BASE_URL}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "Set how many questions you want to generate.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration:\n",
            "  Number of questions: 50\n",
            "  Output file: qa_dataset.json\n",
            "  Question types: factual, procedural, conceptual, comparative, summary\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "NUM_QUESTIONS = 50  # Number of questions to generate\n",
        "OUTPUT_FILE = \"qa_dataset.json\"  # Output filename\n",
        "QUESTION_TYPES = [\n",
        "    \"factual\",      # What is X? Who is Y?\n",
        "    \"procedural\",   # How to do X? What are the steps?\n",
        "    \"conceptual\",   # Explain X. Why is Y important?\n",
        "    \"comparative\",  # Compare X and Y. What's the difference?\n",
        "    \"summary\"       # Summarize X. What is this about?\n",
        "]\n",
        "\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  Number of questions: {NUM_QUESTIONS}\")\n",
        "print(f\"  Output file: {OUTPUT_FILE}\")\n",
        "print(f\"  Question types: {', '.join(QUESTION_TYPES)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check Server Status\n",
        "\n",
        "Verify that the server is running and PDFs are uploaded.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Server is running\n",
            "  Documents uploaded: 112\n"
          ]
        }
      ],
      "source": [
        "# Check server status\n",
        "try:\n",
        "    response = requests.get(f\"{API_BASE_URL}/api/status\", timeout=5)\n",
        "    if response.status_code == 200:\n",
        "        status = response.json()\n",
        "        print(\"✓ Server is running\")\n",
        "        print(f\"  Documents uploaded: {status.get('total_documents', 0)}\")\n",
        "        if status.get('total_documents', 0) == 0:\n",
        "            print(\"\\n⚠️  WARNING: No documents uploaded!\")\n",
        "            print(\"   Please upload PDFs via the web interface before generating questions.\")\n",
        "    else:\n",
        "        print(f\"✗ Server error: {response.status_code}\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Cannot connect to server: {e}\")\n",
        "    print(\"   Make sure the server is running on http://localhost:8000\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Questions and Answers\n",
        "\n",
        "This will use the RAG system to generate questions and reference answers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Generating 50 QA pairs\n",
            "============================================================\n",
            "\n",
            "Step 1: Retrieving diverse content from PDFs...\n",
            "  ✓ Retrieved content from 3 seed questions\n",
            "\n",
            "Step 2: Generating questions using LLM...\n",
            "  ✓ Generated 50 questions\n",
            "\n",
            "Step 3: Generating reference answers using RAG system...\n",
            "  [1/50] Processing: What are the main topics covered in the Machine Le... ✓\n",
            "  [2/50] Processing: What are some key concepts related to machine lear... ✓\n",
            "  [3/50] Processing: What are the procedures described for Feature Sele... ✓\n",
            "  [4/50] Processing: How do intrinsic feature selection methods functio... ✓\n",
            "  [5/50] Processing: What are the pros of using intrinsic feature selec... ✓\n",
            "  [6/50] Processing: What are the cons of intrinsic feature selection m... ✓\n",
            "  [7/50] Processing: How is feature selection embedded in tree-based mo... ✓\n",
            "  [8/50] Processing: What is the relationship between feature selection... ✓\n",
            "  [9/50] Processing: Which models have intrinsic feature selection embe... ✓\n",
            "  [10/50] Processing: What are the pros and cons of linear models in mac... ✓\n",
            "  [11/50] Processing: How do tree-based models compare to linear models?... ✓\n",
            "  [12/50] Processing: What is the difference between Random Forest and G... ✓\n",
            "  [13/50] Processing: What are the evaluation metrics discussed in the P... ✓\n",
            "  [14/50] Processing: How are clustering models different from tree-base... ✓\n",
            "  [15/50] Processing: What are the key differences between a Decision Tr... ✓\n",
            "  [16/50] Processing: How do loss functions relate to machine learning m... ✓\n",
            "  [17/50] Processing: What is the role of missing values in data and fea... ✓\n",
            "  [18/50] Processing: What challenges are associated with imbalanced dat... ✓\n",
            "  [19/50] Processing: In what ways can feature selection enhance model p... ✓\n",
            "  [20/50] Processing: Summarize the main differences between SVMs and Lo... ✓\n",
            "  [21/50] Processing: What are the advantages of using Logistic Regressi... ✓\n",
            "  [22/50] Processing: Why might one choose Random Forest over Logistic R... ✓\n",
            "  [23/50] Processing: What are the main considerations in model comparis... ✓\n",
            "  [24/50] Processing: How does feature selection relate to the objective... ✓\n",
            "  [25/50] Processing: What steps are involved in evaluating machine lear... ✓\n",
            "  [26/50] Processing: What are some examples of intrinsic feature select... ✓\n",
            "  [27/50] Processing: How does imbalanced data affect machine learning m... ✓\n",
            "  [28/50] Processing: What are some methods for handling missing values ... ✓\n",
            "  [29/50] Processing: How does Gradient Boosting differ from Random Fore... ✓\n",
            "  [30/50] Processing: What should be considered when selecting features ... ✓\n",
            "  [31/50] Processing: How do linear models perform compared to tree-base... ✓\n",
            "  [32/50] Processing: What are the benefits of using a Decision Tree ove... ✓\n",
            "  [33/50] Processing: Summarize the pros and cons of using clustering mo... ✓\n",
            "  [34/50] Processing: What are some common feature selection techniques ... ✓\n",
            "  [35/50] Processing: How do loss functions influence the training of ma... ✓\n",
            "  [36/50] Processing: What are the differences between Linear Regression... ✓\n",
            "  [37/50] Processing: In what scenarios would you use Logistic Regressio... ✓\n",
            "  [38/50] Processing: What are some challenges associated with data and ... ✓\n",
            "  [39/50] Processing: How does model comparison aid in selecting the bes... ✓\n",
            "  [40/50] Processing: What are the pros and cons of tree-based models?... ✓\n",
            "  [41/50] Processing: What are the implications of using Linear Models i... ✓\n",
            "  [42/50] Processing: How does feature selection improve the efficiency ... ✓\n",
            "  [43/50] Processing: What are the main advantages of using Random Fores... ✓\n",
            "  [44/50] Processing: How do evaluation metrics impact the assessment of... ✓\n",
            "  [45/50] Processing: What steps are involved in the process of feature ... ✓\n",
            "  [46/50] Processing: How does one compare SVMs and Logistic Regression ... ✓\n",
            "  [47/50] Processing: What factors should be considered in model compari... ✓\n",
            "  [48/50] Processing: What are the main differences between Decision Tre... ✓\n",
            "  [49/50] Processing: What is the role of loss functions in machine lear... ✓\n",
            "  [50/50] Processing: Summarize the process and benefits of feature sele... ✓\n",
            "\n",
            "✓ Generated 50 QA pairs\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Initialize OpenAI client for generating questions\n",
        "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "if not openai_key:\n",
        "    raise ValueError(\"OPENAI_API_KEY not found in environment variables\")\n",
        "\n",
        "client = OpenAI(api_key=openai_key)\n",
        "\n",
        "def generate_qa_pairs(num_questions: int, question_types: List[str]) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Generate question-answer pairs from PDF content.\n",
        "    \n",
        "    Strategy:\n",
        "    1. First, get diverse content from PDFs by asking various questions\n",
        "    2. Use LLM to generate questions based on the content\n",
        "    3. Use RAG system to generate reference answers\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Generating {num_questions} QA pairs\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "    \n",
        "    # Step 1: Get diverse content by asking various seed questions\n",
        "    print(\"Step 1: Retrieving diverse content from PDFs...\")\n",
        "    seed_questions = [\n",
        "        \"What are the main topics covered?\",\n",
        "        \"What are the key concepts?\",\n",
        "        \"What procedures or steps are described?\",\n",
        "        \"What are important definitions?\",\n",
        "        \"What comparisons or analyses are made?\",\n",
        "    ]\n",
        "    \n",
        "    # Get answers to seed questions to understand content\n",
        "    content_summaries = []\n",
        "    for seed_q in seed_questions[:3]:  # Use first 3 to get content overview\n",
        "        try:\n",
        "            response = requests.post(\n",
        "                f\"{API_BASE_URL}/api/ask\",\n",
        "                json={\"question\": seed_q},\n",
        "                timeout=60\n",
        "            )\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                content_summaries.append({\n",
        "                    \"question\": seed_q,\n",
        "                    \"answer\": data.get(\"answer\", \"\"),\n",
        "                    \"citations\": data.get(\"citations\", [])\n",
        "                })\n",
        "        except Exception as e:\n",
        "            print(f\"  Warning: Could not get answer for '{seed_q}': {e}\")\n",
        "    \n",
        "    if not content_summaries:\n",
        "        raise ValueError(\"Could not retrieve content from PDFs. Make sure PDFs are uploaded.\")\n",
        "    \n",
        "    print(f\"  ✓ Retrieved content from {len(content_summaries)} seed questions\")\n",
        "    \n",
        "    # Step 2: Generate questions using LLM\n",
        "    print(\"\\nStep 2: Generating questions using LLM...\")\n",
        "    \n",
        "    # Build context from content summaries\n",
        "    context_text = \"\\n\\n\".join([\n",
        "        f\"Content {i+1}:\\nQ: {item['question']}\\nA: {item['answer'][:500]}...\"\n",
        "        for i, item in enumerate(content_summaries)\n",
        "    ])\n",
        "    \n",
        "    # Create prompt for question generation\n",
        "    prompt = f\"\"\"You are creating a QA dataset for evaluating a RAG (Retrieval-Augmented Generation) system.\n",
        "\n",
        "Based on the following content extracted from PDFs, generate exactly {num_questions} diverse questions.\n",
        "\n",
        "REQUIREMENTS:\n",
        "1. Questions should cover different aspects: {', '.join(question_types)}\n",
        "2. Questions should be answerable based on the provided content\n",
        "3. Mix question types: factual, procedural, conceptual, comparative, summary\n",
        "4. Questions should be clear and specific\n",
        "5. Format as a JSON object with a \"questions\" key containing an array:\n",
        "\n",
        "{{\n",
        "  \"questions\": [\n",
        "    {{\n",
        "      \"question\": \"Your question here?\",\n",
        "      \"question_type\": \"factual|procedural|conceptual|comparative|summary\",\n",
        "      \"expected_topics\": [\"topic1\", \"topic2\"]\n",
        "    }},\n",
        "    ...\n",
        "  ]\n",
        "}}\n",
        "\n",
        "Return ONLY valid JSON, no additional text.\n",
        "\n",
        "Content from PDFs:\n",
        "{context_text}\n",
        "\n",
        "Generate {num_questions} questions now:\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an expert at creating evaluation questions. Always return valid JSON only.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.8,\n",
        "            response_format={\"type\": \"json_object\"}\n",
        "        )\n",
        "        \n",
        "        result_text = response.choices[0].message.content.strip()\n",
        "        \n",
        "        # Parse JSON response\n",
        "        try:\n",
        "            result_json = json.loads(result_text)\n",
        "            # Extract questions list from JSON object\n",
        "            if isinstance(result_json, dict):\n",
        "                questions_list = result_json.get(\"questions\", [])\n",
        "                # If \"questions\" key doesn't exist, try to find any list value\n",
        "                if not questions_list:\n",
        "                    for value in result_json.values():\n",
        "                        if isinstance(value, list):\n",
        "                            questions_list = value\n",
        "                            break\n",
        "            elif isinstance(result_json, list):\n",
        "                questions_list = result_json\n",
        "            else:\n",
        "                raise ValueError(\"Unexpected JSON structure\")\n",
        "        except json.JSONDecodeError:\n",
        "            # If direct parsing fails, try to extract JSON from text\n",
        "            import re\n",
        "            json_match = re.search(r'\\{.*\"questions\".*\\[.*\\].*\\}', result_text, re.DOTALL)\n",
        "            if json_match:\n",
        "                result_json = json.loads(json_match.group(0))\n",
        "                questions_list = result_json.get(\"questions\", [])\n",
        "            else:\n",
        "                # Try to find just the array\n",
        "                array_match = re.search(r'\\[.*\\]', result_text, re.DOTALL)\n",
        "                if array_match:\n",
        "                    questions_list = json.loads(array_match.group(0))\n",
        "                else:\n",
        "                    raise ValueError(\"Could not parse questions from LLM response\")\n",
        "        \n",
        "        if not isinstance(questions_list, list):\n",
        "            raise ValueError(\"LLM did not return a list of questions\")\n",
        "        \n",
        "        print(f\"  ✓ Generated {len(questions_list)} questions\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Error generating questions: {e}\")\n",
        "    \n",
        "    # Step 3: Generate reference answers using RAG system\n",
        "    print(\"\\nStep 3: Generating reference answers using RAG system...\")\n",
        "    qa_pairs = []\n",
        "    skipped_count = 0\n",
        "    \n",
        "    for i, q_item in enumerate(questions_list[:num_questions], 1):\n",
        "        question = q_item.get(\"question\", \"\")\n",
        "        if not question:\n",
        "            continue\n",
        "        \n",
        "        print(f\"  [{i}/{min(len(questions_list), num_questions)}] Processing: {question[:50]}...\", end=\" \", flush=True)\n",
        "        \n",
        "        try:\n",
        "            # Get answer from RAG system\n",
        "            response = requests.post(\n",
        "                f\"{API_BASE_URL}/api/ask\",\n",
        "                json={\"question\": question},\n",
        "                timeout=60\n",
        "            )\n",
        "            \n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                answer = data.get(\"answer\", \"\")\n",
        "                citations = data.get(\"citations\", [])\n",
        "                \n",
        "                # Skip questions that couldn't find answers\n",
        "                if \"couldn't find relevant information\" in answer.lower():\n",
        "                    print(\"✗ (No answer found, skipping)\")\n",
        "                    skipped_count += 1\n",
        "                    continue\n",
        "                \n",
        "                # Extract context from citations for reference\n",
        "                context_parts = []\n",
        "                for cit in citations[:3]:  # Use first 3 citations as context\n",
        "                    context_parts.append(cit.get(\"text_snippet\", \"\")[:200])\n",
        "                context = \" \".join(context_parts)\n",
        "                \n",
        "                qa_pairs.append({\n",
        "                    \"id\": len(qa_pairs) + 1,  # Re-number to avoid gaps\n",
        "                    \"question\": question,\n",
        "                    \"answer\": answer,\n",
        "                    \"context\": context if context else None,\n",
        "                    \"question_type\": q_item.get(\"question_type\", \"factual\"),\n",
        "                    \"citations\": [{\"source\": cit.get(\"source\"), \"pdf\": cit.get(\"pdf_filename\"), \"page\": cit.get(\"page\")} for cit in citations[:5]]\n",
        "                })\n",
        "                print(\"✓\")\n",
        "            else:\n",
        "                print(f\"✗ Error: {response.status_code}\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"✗ Error: {str(e)[:50]}\")\n",
        "            continue\n",
        "    \n",
        "    if skipped_count > 0:\n",
        "        print(f\"\\n  ⚠ Skipped {skipped_count} questions that couldn't find answers\")\n",
        "    \n",
        "    print(f\"\\n✓ Generated {len(qa_pairs)} QA pairs\")\n",
        "    return qa_pairs\n",
        "\n",
        "# Generate QA pairs\n",
        "qa_dataset = generate_qa_pairs(NUM_QUESTIONS, QUESTION_TYPES)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Review Generated Dataset\n",
        "\n",
        "Preview the generated questions and answers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "Generated QA Dataset Preview\n",
            "============================================================\n",
            "\n",
            "Question 1: What are the main topics covered in the Machine Learning Interview Cheat Sheet?\n",
            "Type: factual\n",
            "Answer: Based on the provided context from the PDF documents, the main topics covered in the **Machine Learning Interview Cheat Sheet** are:\n",
            "\n",
            "1. Data and feat...\n",
            "Citations: 5\n",
            "\n",
            "Question 2: What are some key concepts related to machine learning mentioned in the PDFs?\n",
            "Type: factual\n",
            "Answer: ### Key Concepts Related to Machine Learning:\n",
            "\n",
            "- **Data and Feature Engineering**:\n",
            "  - Involves handling missing values, feature selection, and addres...\n",
            "Citations: 5\n",
            "\n",
            "Question 3: What are the procedures described for Feature Selection?\n",
            "Type: procedural\n",
            "Answer: Based on the provided context from the PDF documents, the procedures described for **Feature Selection** include the following steps:\n",
            "\n",
            "1. **Wrapper Fe...\n",
            "Citations: 2\n",
            "\n",
            "... and 47 more questions\n",
            "\n",
            "Total questions: 50\n"
          ]
        }
      ],
      "source": [
        "# Preview dataset\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Generated QA Dataset Preview\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "for i, item in enumerate(qa_dataset[:3], 1):  # Show first 3\n",
        "    print(f\"Question {item['id']}: {item['question']}\")\n",
        "    print(f\"Type: {item.get('question_type', 'N/A')}\")\n",
        "    print(f\"Answer: {item['answer'][:150]}...\")\n",
        "    print(f\"Citations: {len(item.get('citations', []))}\")\n",
        "    print()\n",
        "\n",
        "if len(qa_dataset) > 3:\n",
        "    print(f\"... and {len(qa_dataset) - 3} more questions\\n\")\n",
        "\n",
        "print(f\"Total questions: {len(qa_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Dataset\n",
        "\n",
        "Save the generated dataset to a JSON file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Dataset saved to: qa_dataset.json\n",
            "  Total questions: 50\n",
            "\n",
            "You can now use this file in llm_judge_evaluation.ipynb\n",
            "  Set DATASET_PATH = 'qa_dataset.json' in the evaluation notebook\n"
          ]
        }
      ],
      "source": [
        "# Save dataset\n",
        "output_path = OUTPUT_DIR / OUTPUT_FILE\n",
        "\n",
        "# Clean up the dataset (remove internal fields, keep only what's needed for evaluation)\n",
        "clean_dataset = []\n",
        "for item in qa_dataset:\n",
        "    clean_item = {\n",
        "        \"id\": item.get(\"id\"),\n",
        "        \"question\": item.get(\"question\"),\n",
        "        \"answer\": item.get(\"answer\"),  # Reference answer\n",
        "        \"context\": item.get(\"context\")  # Optional context\n",
        "    }\n",
        "    # Only add context if it exists\n",
        "    if not clean_item[\"context\"]:\n",
        "        del clean_item[\"context\"]\n",
        "    clean_dataset.append(clean_item)\n",
        "\n",
        "with open(output_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(clean_dataset, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"✓ Dataset saved to: {output_path}\")\n",
        "print(f\"  Total questions: {len(clean_dataset)}\")\n",
        "print(f\"\\nYou can now use this file in llm_judge_evaluation.ipynb\")\n",
        "print(f\"  Set DATASET_PATH = '{OUTPUT_FILE}' in the evaluation notebook\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Manual Editing\n",
        "\n",
        "You can manually edit the generated dataset to:\n",
        "- Remove questions you don't want\n",
        "- Add your own questions\n",
        "- Improve reference answers\n",
        "- Add more context\n",
        "\n",
        "Just edit the JSON file directly, or load it here, modify, and save again.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Load, edit, and save dataset\n",
        "# Uncomment and modify as needed\n",
        "\n",
        "# # Load dataset\n",
        "# with open(output_path, 'r', encoding='utf-8') as f:\n",
        "#     dataset = json.load(f)\n",
        "# \n",
        "# # Example: Remove a question\n",
        "# # dataset = [item for item in dataset if item['id'] != 5]\n",
        "# \n",
        "# # Example: Add a custom question\n",
        "# # dataset.append({\n",
        "# #     \"id\": len(dataset) + 1,\n",
        "# #     \"question\": \"Your custom question?\",\n",
        "# #     \"answer\": \"Your reference answer\",\n",
        "# #     \"context\": \"Optional context\"\n",
        "# # })\n",
        "# \n",
        "# # Save modified dataset\n",
        "# with open(output_path, 'w', encoding='utf-8') as f:\n",
        "#     json.dump(dataset, f, indent=2, ensure_ascii=False)\n",
        "# \n",
        "# print(\"✓ Dataset updated\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
